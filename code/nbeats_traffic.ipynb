{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_forecasting import Baseline, NBeats, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import MAE, MAPE, MASE, RMSE, SMAPE\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from thesis.dataloading import load_traffic\n",
    "from thesis.metrics import METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "ROOT_DIR = Path(\"output\", \"traffic\", \"nbeats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "data, freq = load_traffic(\"./datasets/traffic\")\n",
    "data = (\n",
    "    data\n",
    "    .dropna()\n",
    "    .reset_index()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"time_idx\"})\n",
    "    .set_index([\"time_idx\", \"date\"])\n",
    "    .rename_axis(\"series\", axis=\"columns\")\n",
    "    .stack()\n",
    "    .rename(\"value\")  # type: ignore\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_length = 504\n",
      "output_length = 168\n",
      "validation_cutoff = 4824\n",
      "training_cutoff = 4152\n",
      "data['time_idx'].max() = 4992\n"
     ]
    }
   ],
   "source": [
    "# slicing configuration\n",
    "horizon = pd.Timedelta(7, \"day\")\n",
    "\n",
    "output_length = horizon // freq\n",
    "input_length = 3 * output_length  # TODO: Experiment with larger input lengths\n",
    "validation_cutoff = data[\"time_idx\"].max() - output_length\n",
    "training_cutoff = validation_cutoff - 4 * output_length\n",
    "\n",
    "assert pd.DataFrame.equals(\n",
    "    data[(data[\"series\"] == \"MT_001\") & (data[\"time_idx\"] <= validation_cutoff)],\n",
    "    data[(data[\"series\"] == \"MT_001\") & (data[\"date\"] <= data[\"date\"].max() - horizon)],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{input_length = }\\n{output_length = }\\n{validation_cutoff = }\\n{training_cutoff = }\\n{data['time_idx'].max() = }\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) = 174100\n",
      "len(val) = 25250\n",
      "len(test) = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1187: UserWarning: If predicting, no randomization should be possible - setting stop_randomization=True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloaders\n",
    "train = TimeSeriesDataSet(\n",
    "    data[data[\"time_idx\"] <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"series\"],\n",
    "    # only unknown variable is \"value\" - and N-Beats can also not take any additional variables\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    max_encoder_length=input_length,\n",
    "    max_prediction_length=output_length,\n",
    ")\n",
    "val = TimeSeriesDataSet.from_dataset(\n",
    "    train,\n",
    "    data[data[\"time_idx\"] <= validation_cutoff],\n",
    "    min_prediction_idx=training_cutoff + 1,\n",
    ")\n",
    "test = TimeSeriesDataSet.from_dataset(\n",
    "    train,\n",
    "    data,\n",
    "    # min_prediction_idx=validation_cutoff + 1,\n",
    "    predict=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"{len(train) = }\\n{len(val) = }\\n{len(test) = }\")\n",
    "\n",
    "batch_size = 1024  # TODO: Use smaller batch sizes to avoid being stuck at local minima\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_dataloader = val.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    ")\n",
    "test_dataloader = test.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d37f2f99e64116822bee1856763bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE            0.03496846556663513\n",
      "        test_MAPE            1.585340976715088\n",
      "        test_MASE            3.383080244064331\n",
      "        test_RMSE           0.04812637344002724\n",
      "       test_SMAPE           0.7349310517311096\n",
      "        test_loss           0.7349310517311096\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae865288b6fc429d874292ae042ca748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE            0.03413664177060127\n",
      "        test_MAPE           0.7554436326026917\n",
      "        test_MASE           3.3722774982452393\n",
      "        test_RMSE           0.0483693964779377\n",
      "       test_SMAPE           0.8089524507522583\n",
      "        test_loss           0.8089524507522583\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "baseline = Baseline(\n",
    "    logging_metrics=nn.ModuleList([SMAPE(), MAE(), RMSE(), MAPE(), MASE()])\n",
    ")\n",
    "baseline_trainer = pl.Trainer(logger=False, enable_checkpointing=False)\n",
    "\n",
    "print(\"Validation Baseline\")\n",
    "_ = baseline_trainer.test(baseline, val_dataloader)\n",
    "print(\"Test Baseline\")\n",
    "_ = baseline_trainer.test(baseline, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/pytorch_forecasting/models/nbeats/sub_modules.py:154: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  coefficients = torch.tensor([backcast_linspace**i for i in range(thetas_dim)], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = NBeats.from_dataset(\n",
    "    train,\n",
    "    expansion_coefficient_lengths=[3, 12],\n",
    "    widths=[128, 512],\n",
    "    learning_rate=1e-3,\n",
    "    log_interval=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\", verbose=False\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", verbose=False)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    default_root_dir=ROOT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: output/traffic/nbeats/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 2.9 M \n",
      "-----------------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.615    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b609f652043a482eae2998af5b0f66c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3e7a0b02ae45709046accfab0d86a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07598e9cce8747c5adc75fe42abd97d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df837123dd3843b8a5991dc5300a1c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed17ce1b59694b2eaf69ab6aea563453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5797fa7c7d564e40bd838c14df7852af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad16b02c24744b6d803c4421109e18c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4d877a85504d5cb303792cf556a51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8eff28a5df41caa35d1d81be699541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6df792b70b943358996c1ec28f747b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5799860404234285b3bdb9d1fa738085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Restoring states from the checkpoint path at output/traffic/nbeats/lightning_logs/version_0/checkpoints/epoch=8-step=1530.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at output/traffic/nbeats/lightning_logs/version_0/checkpoints/epoch=8-step=1530.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d764bd568c244573bdc198bb8f828ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE           0.009415020234882832\n",
      "        test_MAPE           0.21913982927799225\n",
      "        test_MASE           0.8594407439231873\n",
      "        test_RMSE           0.02147715725004673\n",
      "       test_SMAPE           0.20789937674999237\n",
      "        test_loss           0.8594407439231873\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "_ = trainer.test(ckpt_path=\"best\", dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path  # type: ignore\n",
    "best_model = NBeats.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/konstantinos/projects/thesis/code/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "out = best_model.predict(\n",
    "    test_dataloader, mode=\"raw\", return_x=True, return_y=True, return_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    metric_fn.__name__: {\n",
    "        name: metric_fn(y_true.cpu().numpy(), y_pred.cpu().numpy()).item()\n",
    "        for name, y_true, y_pred in zip(\n",
    "            out.index[\"series\"],\n",
    "            out.y[0],\n",
    "            out.output.prediction,\n",
    "        )\n",
    "    }\n",
    "    for metric_fn in METRICS\n",
    "}\n",
    "\n",
    "pd.DataFrame(performance).to_csv(Path(trainer.log_dir, \"performance.csv\"))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "summary_writer: SummaryWriter = trainer.logger.experiment  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot preds\n",
    "for i, name in out.index[\"series\"].items():\n",
    "    fig = best_model.plot_prediction(\n",
    "        out.x,\n",
    "        out.output,\n",
    "        idx=i,\n",
    "    )\n",
    "    summary_writer.add_figure(f\"prediction/{name}\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interpretation\n",
    "for i, name in out.index[\"series\"].items():\n",
    "    fig = best_model.plot_interpretation(out.x, out.output, idx=i)\n",
    "    summary_writer.add_figure(f\"interpretation/{name}\", fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
